---
title: "R Tutorial 010: Linear models"
author: "RichardOnData"
date: "12/3/2020"
output: 
  html_document:
    code_folding: "show"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

```{r Load libraries and data}
library(tidyverse)
library(broom)
library(AER)

mtcars <- mtcars
data(CreditCard)
```

In this tutorial we will go over creating statistical models in R.   Machine learning is outside of the scope of this tutorial.   We'll use the "mtcars" dataset to see an example of a linear regression and the "CreditCard" dataset from the AER package to see an example of a logistic regression.

Documentation on the datasets:

  * "mtcars": https://rstudio-pubs-static.s3.amazonaws.com/61800_faea93548c6b49cc91cd0c5ef5059894.html
  * "CreditCard": https://rdrr.io/cran/AER/man/CreditCard.html
  
This is one of the best tutorials out there on linear models in R: https://socviz.co/modeling.html 

### lm() example ###

We will create a linear regression of the "mpg" variable from the "mtcars" dataset on all other variables.   Before doing any sort of modeling, it is appropriate to have a feel for the data's structure.   The `summary()` function is an excellent starting point.

```{r Summary of "mtcars" dataset}
summary(mtcars)
```

The variables "cyl", "vs", "am", and "gear" are coded as numerics here.   However, they should be coded as categorical variables.   This is a very common error that beginners make.   It is not always straightforward when to code a variable as numeric as opposed to categorical; however we will make the change here.   

```{r Change "mtcars" columns to factors}
mtcars <- mtcars %>%
  mutate(across(.cols = c("cyl", "vs", "am", "gear"), .fns = factor))
```

Now our dataset is in the appropriate format for fitting the linear model.   We will now look at the following things: the `lm()` function itself and passing a formula to it, calling the summary of the fit, then looking at the structure of the fit and seeing how we can extract various individual components from the output.   Let's start by calling the most basic possible regression model.

```{r Fit initial lm for "mtcars"}
linReg <- lm(mpg ~ ., data = mtcars)
linReg
```

This returns the model call as well as the coefficients, though this is not very helpful in and of itself.   The object "linReg" is actually an object of class "lm", which is just a list with various components and attributes.

We used only two arguments here: a model formula, and the data frame.   The "." expression at the end is a shortcut telling R to pass all of the other variable terms into the model, other than the independent variable specified.   I recommend expressing the formula first as a string, in the event you try multiple methods.  Let's try that now, with fewer terms.   We will also add an interaction term for "hp:wt", and we will perform a square root transformation of the "disp" variable, and we'll call the `summary()` function on this model object.

```{r Fit modified lm for "mtcars"}
formula <- "mpg ~ cyl + sqrt(disp) + hp + drat + wt + qsec + hp:wt"
linReg <- lm(formula, data = mtcars)
summary(linReg)
```

This is much more informative!  We are provided the model call, a five-number summary of the residuals, a table of the coefficients including slope parameter estimates, the standard errors of these estimates, their corresponding t-statistics and p-values, codes making it easy to indicate if these are significant, and then residual standard error, multiple and adjusted R-squared, and the F-statistic for the model fit and its corresponding p-value.

It's helpful to understand what happens when we access the structure of both the "linReg" object and the summary of it.

```{r Return structure of the "lm" object}
str(linReg)
```

There's a lot there.   The structure of the summary is a little cleaner.

```{r Return structure of the summary of the "lm" object}
str(summary(linReg))
```

It is important to be familiar with these structures.   Understanding what is actually being created by these functions will build your intuition of the R programming language as well as make it significantly easier to debug issues.   Additionally, it is sometimes necessary to programatically access components of the regression fit and use them as output somewhere else.

As an example, let's access the coefficients table and arrange it by descending absolute value t-statistic.

```{r Return coefficient table}
summaryList <- summary(linReg)
coef <- data.frame(summaryList$coefficients)
coef <- coef %>%
  arrange(desc(abs(t.value)))
coef
```

Note that the "coef" object that was extracted is a named matrix.   The transformation to a data frame did change the column names.

This was generally fairly complex.   However, we can use the "broom" package from the tidyverse in order to coerce model output into a "tidy" format, and make our lives a lot easier.   There are three key functions in this library: `tidy()`, `glance()`, and `augment()`.   Let's start by running the `tidy()` function on the fit.

```{r tidy() example}
tidy(linReg)
```

This is a "tidy" version of the model output from before.   Next, let's use the `glance()` function.

```{r glance() example}
glance(linReg)
```

This provides us a lot of very helpful summary information.   Next, let's use the `augment()` function.    This will add information from the model into the original datasets.

```{r augment() example}
augmentedCars <- augment(linReg, data = mtcars)
augmentedCars
```

<br>

### glm() example ###

Next, let's see an example with "glm".   We will switch gears and use the "CreditCard" dataset now.  As before, let's start with a summary of the dataset.

```{r Summary of "CreditCard" dataset}
summary(CreditCard)
```

There are a few problems to point out.   First of all, the "share" variable has a scale in percentage terms.   This can make it challenging to interpret, so we will transform it to a percentage scale.   The "expenditure" variable has at least one outlier on the extreme side.   For now, we'll just exclude this variable from the analysis.   Additionally, the "majorcards" variable is coded as a numeric when it is a factor.

```{r Fix issues with the variables}
CreditCard$share <- CreditCard$share * 100
CreditCard$majorcards <- factor(CreditCard$majorcards)
```

We are ready to fit a logistic regression.   The formula for this is `glm()`.  It is important here to point out the "family" argument to this function.  The default is "binomial" - this corresponds to the link function for a generalized linear model.   This is what we want for a logistic regression, but note that other options do exist.

```{r Fit logistic regression to "CreditCard" data}
formula <- "card ~ reports + age + income + share + owner + selfemp + dependents + months + majorcards + active"
logReg <- glm(formula, family = "binomial", data = CreditCard)
summary(logReg)
```

We are just getting started with all the options in linear/statistical modeling in R.   Remember that the language was built by statisticians for other statisticians - this is the fun stuff!!

